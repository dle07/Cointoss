# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16qegalCbpM20eCCdlv5wmzKvd7X83neI
"""

import datetime
import numpy as np
import pandas as pd
import yfinance as yf
from fastapi import FastAPI, Response
from tensorflow.keras.models import load_model
from sklearn.preprocessing import MinMaxScaler
from datetime import date
from keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences


mlApp = FastAPI()
#Load models
time_series_model = load_model("QQQ_Model.h5")

sentiment_model = load_model("SAM.h5")


@mlApp.get("/ml/time-series")
def time_series_test(tickerSymbol):
    #set sequence length to thee lengththe model was trained with
    sequence_length = 50
    df = yf.download(tickerSymbol)
    FEATURES = ['High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close']
    df_filtered = df.filter(FEATURES)
    np_data_unscaled = np.array(df_filtered)

    #Scaler for x values
    scaler = MinMaxScaler()
    scaler.fit(np_data_unscaled)

    #scaler for prediction
    scaler_pred = MinMaxScaler()
    df_close = pd.DataFrame(df_filtered['Close'])
    scaler_pred.fit(df_close)

    df_temp = df_filtered[-sequence_length:].values
    df_temp_scaled = scaler.transform(df_temp)

    x_pred = []
    x_pred.append(df_temp_scaled)

    pred_price_scaled = time_series_model.predict(np.array(x_pred))
    pred_price_unscaled = scaler_pred.inverse_transform(pred_price_scaled.reshape(-1, 1))

    predicted_price = np.round(pred_price_unscaled.ravel()[0], 2)
    return {"prediction": predicted_price.item()}


@mlApp.get("/ml/sentiment")
def sentiment_test(text):

    df = pd.read_csv("stock_sentiment_data.csv")
    tweet_df = df[['Tweet_Text','Sentiment']]
    tweet_df = tweet_df[tweet_df['Sentiment'] != 'Neutral']
    sentiment_label = tweet_df.Sentiment.factorize()

    tweet = tweet_df.Tweet_Text.values
    tokenizer = Tokenizer(num_words=5000)
    tokenizer.fit_on_texts(tweet)
    vocab_size = len(tokenizer.word_index) + 1
    encoded_docs = tokenizer.texts_to_sequences(tweet)
    padded_sequence = pad_sequences(encoded_docs, maxlen=200)


    tw = tokenizer.texts_to_sequences([text])
    tw = pad_sequences(tw,maxlen=200)
    prediction = int(sentiment_model.predict(tw).round().item())
    return {"sentiment_prediction": sentiment_label[1][prediction]}
